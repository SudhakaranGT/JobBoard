{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.39.3)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.9.3)\n",
      "Requirement already satisfied: torch in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: click in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.13.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wordcloud) (9.5.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wordcloud) (3.7.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->wordcloud) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->wordcloud) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->wordcloud) (1.4.5)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ssn\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wget nltk PyPDF2 transformers wordcloud torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings, wget\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Flatten, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from transformers import AutoTokenizer, TFDistilBertForSequenceClassification\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from wordcloud import WordCloud\n",
    "wget.download(\"https://raw.githubusercontent.com/yogawicaksana/helper_prabowo/main/helper_prabowo_ml.py\",out=\"helper_prabowo_ml.py\")\n",
    "from helper_prabowo_ml import clean_html, remove_links, remove_special_characters, removeStopWords, remove_, remove_digits, lower, email_address, non_ascii, punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills * Programming Languages: Python (pandas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\nMay 2013 to May 2017 B.E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Areas of Interest Deep Learning, Control Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>Education Details \\r\\n MCA   YMCAUST,  Faridab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Category                                             Resume\n",
       "0  Data Science  Skills * Programming Languages: Python (pandas...\n",
       "1  Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
       "2  Data Science  Areas of Interest Deep Learning, Control Syste...\n",
       "3  Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
       "4  Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"UpdatedResumeDataSet.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of available jobs: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of available jobs:\", df.Category.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Data Science': 0,\n",
       " 'HR': 1,\n",
       " 'Advocate': 2,\n",
       " 'Arts': 3,\n",
       " 'Web Designing': 4,\n",
       " 'Mechanical Engineer': 5,\n",
       " 'Sales': 6,\n",
       " 'Health and fitness': 7,\n",
       " 'Civil Engineer': 8,\n",
       " 'Java Developer': 9,\n",
       " 'Business Analyst': 10,\n",
       " 'SAP Developer': 11,\n",
       " 'Automation Testing': 12,\n",
       " 'Electrical Engineering': 13,\n",
       " 'Operations Manager': 14,\n",
       " 'Python Developer': 15,\n",
       " 'DevOps Engineer': 16,\n",
       " 'Network Security Engineer': 17,\n",
       " 'PMO': 18,\n",
       " 'Database': 19,\n",
       " 'Hadoop': 20,\n",
       " 'ETL Developer': 21,\n",
       " 'DotNet Developer': 22,\n",
       " 'Blockchain': 23,\n",
       " 'Testing': 24}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict = {}\n",
    "\n",
    "for idx, label in enumerate(df.Category.unique()):\n",
    "    labels_dict[label] = idx\n",
    "\n",
    "labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(data,col):\n",
    "    data[col] = data[col].apply(func=clean_html)\n",
    "    data[col] = data[col].apply(func=remove_)\n",
    "    data[col] = data[col].apply(func=removeStopWords)\n",
    "    data[col] = data[col].apply(func=remove_digits)\n",
    "    data[col] = data[col].apply(func=remove_links)\n",
    "    data[col] = data[col].apply(func=remove_special_characters)\n",
    "    data[col] = data[col].apply(func=punct)\n",
    "    data[col] = data[col].apply(func=non_ascii)\n",
    "    data[col] = data[col].apply(func=email_address)\n",
    "    data[col] = data[col].apply(func=lower)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Category = df.Category.apply(func=lambda x: labels_dict[x])\n",
    "df.Category = df.Category.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>skills programming languages python pandas num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>education details may may b e uitrgpv data sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>areas interest deep learning control system de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>skills r python sap hana tableau sap hana sql ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>education details mca ymcaust faridabad haryan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                             Resume\n",
       "0         0  skills programming languages python pandas num...\n",
       "1         0  education details may may b e uitrgpv data sci...\n",
       "2         0  areas interest deep learning control system de...\n",
       "3         0  skills r python sap hana tableau sap hana sql ...\n",
       "4         0  education details mca ymcaust faridabad haryan..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df = text_preprocess(df,'Resume')\n",
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"manishiitg/distilbert-resume-parts-classify\")\n",
    "bert_model = TFDistilBertForSequenceClassification.from_pretrained(\"manishiitg/distilbert-resume-parts-classify\",from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(preprocessed_df,test_size=0.3,shuffle=True,random_state=101)\n",
    "max_resume_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer(text=train_df.Resume.tolist(),\n",
    "                   add_special_tokens=True,\n",
    "                   padding=True,\n",
    "                   truncation=True,\n",
    "                   max_length=max_resume_len,\n",
    "                   return_tensors='tf',\n",
    "                   return_attention_mask=True,\n",
    "                   return_token_type_ids=False,\n",
    "                   verbose=1)\n",
    "\n",
    "X_test = tokenizer(text=test_df.Resume.tolist(),\n",
    "                  add_special_tokens=True,\n",
    "                  padding=True,\n",
    "                  truncation=True,\n",
    "                  max_length=max_resume_len,\n",
    "                  return_tensors='tf',\n",
    "                  return_attention_mask=True,\n",
    "                  return_token_type_ids=False,\n",
    "                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = Input(shape=(max_resume_len,),dtype=tf.int32,name='input_ids')\n",
    "attention_masks = Input(shape=(max_resume_len,),dtype=tf.int32,name='attention_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.src.engine.input_layer.InputLayer at 0x1a6dd50f6d0>,\n",
       " <keras.src.engine.input_layer.InputLayer at 0x1a6dd51ac10>,\n",
       " <transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForSequenceClassification at 0x1a6dace2290>,\n",
       " <keras.src.layers.reshaping.flatten.Flatten at 0x1a6aa85e950>,\n",
       " <keras.src.layers.core.dense.Dense at 0x1a6dd51afd0>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x1a6ddb6d990>,\n",
       " <keras.src.layers.regularization.dropout.Dropout at 0x1a6a9c5e950>,\n",
       " <keras.src.layers.core.dense.Dense at 0x1a6ddb867d0>,\n",
       " <keras.src.layers.regularization.dropout.Dropout at 0x1a6aa78a210>,\n",
       " <keras.src.layers.core.dense.Dense at 0x1a6ddba3090>,\n",
       " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x1a6a9e94e10>,\n",
       " <keras.src.layers.regularization.dropout.Dropout at 0x1a6dd5fe1d0>,\n",
       " <keras.src.layers.core.dense.Dense at 0x1a6ddba3b10>,\n",
       " <keras.src.layers.regularization.dropout.Dropout at 0x1a6dd546c10>,\n",
       " <keras.src.layers.core.dense.Dense at 0x1a6ddb26c90>,\n",
       " <keras.src.layers.core.dense.Dense at 0x1a6ddbb1150>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings = bert_model(input_ids,attention_mask=attention_masks)[0] # 0 --> final hidden state, 1 --> pooling output\n",
    "\n",
    "output = Flatten()(word_embeddings)\n",
    "output = Dense(units=1024,activation='relu')(output)\n",
    "output = BatchNormalization()(output)\n",
    "output = Dropout(0.25)(output)\n",
    "output = Dense(units=512,activation='relu')(output)\n",
    "output = Dropout(0.25)(output)\n",
    "output = Dense(units=256,activation='relu')(output)\n",
    "output = BatchNormalization()(output)\n",
    "output = Dropout(0.25)(output)\n",
    "output = Dense(units=128,activation='relu')(output)\n",
    "output = Dropout(0.25)(output)\n",
    "output = Dense(units=64,activation='relu')(output)\n",
    "output = Dense(units=25,activation='softmax')(output)\n",
    "\n",
    "model = Model(inputs=[input_ids,attention_masks],outputs=output)\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 200)]                0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 200)]                0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf_distil_bert_for_sequenc  TFSequenceClassifierOutput   6696270   ['input_ids[0][0]',           \n",
      " e_classification_1 (TFDist  (loss=None, logits=(None,    0          'attention_mask[0][0]']      \n",
      " ilBertForSequenceClassific  12),                                                                 \n",
      " ation)                       hidden_states=None, atten                                           \n",
      "                             tions=None)                                                          \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 12)                   0         ['tf_distil_bert_for_sequence_\n",
      "                                                                    classification_1[0][0]']      \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 1024)                 13312     ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 1024)                 4096      ['dense_6[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)        (None, 1024)                 0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 512)                  524800    ['dropout_44[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)        (None, 512)                  0         ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 256)                  131328    ['dropout_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 256)                  1024      ['dense_8[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)        (None, 256)                  0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 128)                  32896     ['dropout_46[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)        (None, 128)                  0         ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 64)                   8256      ['dropout_47[0][0]']          \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 25)                   1625      ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 67680037 (258.18 MB)\n",
      "Trainable params: 67677477 (258.17 MB)\n",
      "Non-trainable params: 2560 (10.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.metrics import SparseCategoricalAccuracy\n",
    "\n",
    "adam = Adam(learning_rate=5e-5, epsilon=2e-8, clipnorm=1.0)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=[SparseCategoricalAccuracy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:From c:\\Users\\SSN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "22/22 [==============================] - ETA: 0s - loss: 3.6560 - sparse_categorical_accuracy: 0.0505 WARNING:tensorflow:Early stopping conditioned on metric `val_balanced_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_balanced_accuracy available, skipping.\n",
      "22/22 [==============================] - 466s 19s/step - loss: 3.6560 - sparse_categorical_accuracy: 0.0505 - val_loss: 3.2073 - val_sparse_categorical_accuracy: 0.0311\n",
      "Epoch 2/500\n",
      "22/22 [==============================] - ETA: 0s - loss: 3.4979 - sparse_categorical_accuracy: 0.0565 WARNING:tensorflow:Early stopping conditioned on metric `val_balanced_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_balanced_accuracy available, skipping.\n",
      "22/22 [==============================] - 361s 16s/step - loss: 3.4979 - sparse_categorical_accuracy: 0.0565 - val_loss: 3.2028 - val_sparse_categorical_accuracy: 0.0277\n",
      "Epoch 3/500\n",
      "22/22 [==============================] - ETA: 0s - loss: 3.4064 - sparse_categorical_accuracy: 0.0475 WARNING:tensorflow:Early stopping conditioned on metric `val_balanced_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_balanced_accuracy available, skipping.\n",
      "22/22 [==============================] - 283s 13s/step - loss: 3.4064 - sparse_categorical_accuracy: 0.0475 - val_loss: 3.2142 - val_sparse_categorical_accuracy: 0.0277\n",
      "Epoch 4/500\n",
      "22/22 [==============================] - ETA: 0s - loss: 3.3293 - sparse_categorical_accuracy: 0.0624 WARNING:tensorflow:Early stopping conditioned on metric `val_balanced_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_balanced_accuracy available, skipping.\n",
      "22/22 [==============================] - 253s 12s/step - loss: 3.3293 - sparse_categorical_accuracy: 0.0624 - val_loss: 3.2213 - val_sparse_categorical_accuracy: 0.0242\n",
      "Epoch 5/500\n",
      "22/22 [==============================] - ETA: 0s - loss: 3.2177 - sparse_categorical_accuracy: 0.0713 WARNING:tensorflow:Early stopping conditioned on metric `val_balanced_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_balanced_accuracy available, skipping.\n",
      "22/22 [==============================] - 249s 11s/step - loss: 3.2177 - sparse_categorical_accuracy: 0.0713 - val_loss: 3.1814 - val_sparse_categorical_accuracy: 0.0588\n",
      "Epoch 6/500\n",
      "22/22 [==============================] - ETA: 0s - loss: 3.1752 - sparse_categorical_accuracy: 0.0892 WARNING:tensorflow:Early stopping conditioned on metric `val_balanced_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_balanced_accuracy available, skipping.\n",
      "22/22 [==============================] - 271s 12s/step - loss: 3.1752 - sparse_categorical_accuracy: 0.0892 - val_loss: 3.1526 - val_sparse_categorical_accuracy: 0.0900\n",
      "Epoch 7/500\n",
      "22/22 [==============================] - ETA: 0s - loss: 3.1010 - sparse_categorical_accuracy: 0.1100 WARNING:tensorflow:Early stopping conditioned on metric `val_balanced_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_balanced_accuracy available, skipping.\n",
      "22/22 [==============================] - 276s 12s/step - loss: 3.1010 - sparse_categorical_accuracy: 0.1100 - val_loss: 3.1074 - val_sparse_categorical_accuracy: 0.1522\n",
      "Epoch 8/500\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.9858 - sparse_categorical_accuracy: 0.1263 WARNING:tensorflow:Early stopping conditioned on metric `val_balanced_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_balanced_accuracy available, skipping.\n",
      "22/22 [==============================] - 406s 19s/step - loss: 2.9858 - sparse_categorical_accuracy: 0.1263 - val_loss: 3.0608 - val_sparse_categorical_accuracy: 0.2526\n",
      "Epoch 9/500\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.8020 - sparse_categorical_accuracy: 0.1634 WARNING:tensorflow:Early stopping conditioned on metric `val_balanced_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_balanced_accuracy available, skipping.\n",
      "22/22 [==============================] - 350s 16s/step - loss: 2.8020 - sparse_categorical_accuracy: 0.1634 - val_loss: 2.9944 - val_sparse_categorical_accuracy: 0.2457\n",
      "Epoch 10/500\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.5436 - sparse_categorical_accuracy: 0.2779 WARNING:tensorflow:Early stopping conditioned on metric `val_balanced_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_balanced_accuracy available, skipping.\n",
      "22/22 [==============================] - 375s 17s/step - loss: 2.5436 - sparse_categorical_accuracy: 0.2779 - val_loss: 2.8572 - val_sparse_categorical_accuracy: 0.3218\n",
      "Epoch 11/500\n",
      "22/22 [==============================] - ETA: 0s - loss: 2.4062 - sparse_categorical_accuracy: 0.3150 WARNING:tensorflow:Early stopping conditioned on metric `val_balanced_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_balanced_accuracy available, skipping.\n",
      "22/22 [==============================] - 472s 22s/step - loss: 2.4062 - sparse_categorical_accuracy: 0.3150 - val_loss: 2.7020 - val_sparse_categorical_accuracy: 0.3183\n",
      "Epoch 12/500\n",
      " 1/22 [>.............................] - ETA: 5:28 - loss: 2.4347 - sparse_categorical_accuracy: 0.2812"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_balanced_accuracy',patience=250,verbose=1,mode='max',restore_best_weights=True)\n",
    "mc = ModelCheckpoint('resume_parser.h5',monitor='val_balanced_accuracy',mode='max',verbose=1,save_best_only=True)\n",
    "\n",
    "r = model.fit(x={'input_ids': X_train['input_ids'], 'attention_mask': X_train['attention_mask']},\n",
    "             y=train_df.Category,\n",
    "             epochs=500,\n",
    "             batch_size=32,\n",
    "             callbacks=[es,mc],\n",
    "             validation_data=({'input_ids': X_test['input_ids'], 'attention_mask': X_test['attention_mask']},test_df.Category))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
